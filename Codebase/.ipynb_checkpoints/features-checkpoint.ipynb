{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244c8f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import sys\n",
    "import networkx as nx\n",
    "import spacy\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "random.seed(100)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4bd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff79a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNetwork(sentence_list, ent1_word_idx, ent2_word_idx):\n",
    "    try:\n",
    "        sentence = ' '.join(sentence_list)\n",
    "        doc = nlp(sentence)\n",
    "        edges = []\n",
    "        for word_idx, token in enumerate(doc):\n",
    "            for child in token.children:\n",
    "                edges.append((token.i,\n",
    "                          child.i))\n",
    "\n",
    "        graph = nx.Graph(edges)\n",
    "        ## If shortest path not found\n",
    "        try:\n",
    "            shortest_path_length = nx.shortest_path_length(graph, source=ent1_word_idx, target=ent2_word_idx)\n",
    "            shortest_path = nx.shortest_path(graph, source=ent1_word_idx, target=ent2_word_idx)\n",
    "        except: \n",
    "            shortest_path_length = -1\n",
    "            shortest_path = \"no_path_found\"\n",
    "        return shortest_path_length, shortest_path\n",
    "    except:\n",
    "        print(\"NETWORK - NO PATH FOUND: \", sentence_list, ent1_word_idx, ent2_word_idx)\n",
    "        print(traceback.format_exc())\n",
    "        return -1, \"no_path_found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae270f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(row, sentence, entity):\n",
    "    try:\n",
    "        return sentence.index(entity.split(\" \")[0]) + 1\n",
    "    except:\n",
    "        print(\"INDEX NOT FOUND - \", sentence, entity, entity.split(\" \")[0])\n",
    "        print(traceback.format_exc())\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f335e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(file):\n",
    "    try:\n",
    "        # df = pd.read_csv(file, sep=\"\\t\", index_col=False, dtype={'text': str, 'entity type': str, 'pos':str , 'tag': str, 'dep': str, 'sent_index': int, 'entity mention ID': str})                           \n",
    "        df = pd.read_csv(file, index_col=False)  ## For ACE2004 and ACE2005 as sep is different. \n",
    "        df = df.rename(columns={\"entity_id\": \"entity mention ID\", \"sent_idx\": \"sent_index\", \"entity_type\" : \"entity type\"})\n",
    "        df.astype({'text': str, 'entity type': str, 'pos':str , 'dep': str, 'sent_index': int, 'entity mention ID': str})\n",
    "        df = df.fillna(\"\")\n",
    "        # filtered_df = df.where(df[\"entity mention ID\"]!=\"\").groupby([\"sent_index\", \"entity mention ID\"], as_index=False).agg({'text': ' '.join, 'entity type': '-'.join, 'pos' : '-'.join, 'tag' : '-'.join,'dep': '-'.join})\n",
    "         ## For ACE2004, ACE2005, tacred, kbp37 as no tag exists\n",
    "        filtered_df = df.where(df[\"entity mention ID\"]!=\"\").groupby([\"sent_index\", \"entity mention ID\"], as_index=False).agg({'text': ' '.join, 'entity type': '-'.join, 'pos' : '-'.join, 'dep': '-'.join}) \n",
    "\n",
    "        ## Calculating entity-entity distances per sentence\n",
    "        # sent_df = filtered_df.groupby([\"sent_index\"], as_index=False).agg({'text': list, 'entity type': list, 'pos' : list, 'tag' : list, 'dep': list})\n",
    "         ##  For ACE2004, ACE2005, tacred, kbp37 as no tag exists\n",
    "        sent_df = filtered_df.groupby([\"sent_index\"], as_index=False).agg({'text': list, 'entity type': list, 'pos' : list, 'dep': list})\n",
    "\n",
    "        text_pairs = []\n",
    "        ent_type_pairs = []\n",
    "        pos_pairs = []\n",
    "        tag_pairs = []\n",
    "        dep_pairs = []\n",
    "        \n",
    "        pos_ignore_list = [\"PRON\", \"PROPN-PART\", \"DET\", \"AUX\", \"CONJ\", \"CCONJ\", \"PART\",\"PUNCT\", \"SYM\"]\n",
    "\n",
    "        for index, row in sent_df.iterrows():\n",
    "            text_pairs.append(list(combinations(row[\"text\"], r=2)))\n",
    "            ent_type_pairs.append(list(combinations(row[\"entity type\"], r=2)))\n",
    "            pos_pairs.append(list(combinations(row[\"pos\"], r=2)))\n",
    "            dep_pairs.append(list(combinations(row[\"dep\"], r=2)))\n",
    "            # tag_pairs.append(list(combinations(row[\"tag\"], r=2)))  ## For  ACE2004, ACE2005, tacred, kbp37 as no tag exists\n",
    "\n",
    "        sent_entity_df = pd.DataFrame()\n",
    "        sent_entity_df[\"sent_index\"] = sent_df[\"sent_index\"]\n",
    "        sent_entity_df[\"entity_pairs\"] = text_pairs\n",
    "        sent_entity_df[\"ent_type_pairs\"] = ent_type_pairs\n",
    "        sent_entity_df[\"pos_pairs\"] = pos_pairs\n",
    "        sent_entity_df[\"dep_pairs\"] = dep_pairs\n",
    "        # sent_entity_df[\"tag_pairs\"] = tag_pairs  ## For ACE2004, ACE2005, tacred, kbp37 as no tag exists \n",
    "\n",
    "\n",
    "        final_df = sent_entity_df.set_index('sent_index').apply(lambda x: x.apply(pd.Series).stack()).reset_index().drop('level_1', 1)\n",
    "\n",
    "        sentences = df.groupby(['sent_index'], as_index=False).agg({'text': list, 'dep': list})\n",
    "        sentences[\"sentence_length\"] = sentences.apply(lambda x : len(x[\"text\"]), axis=1)\n",
    "        sentences[\"root_index\"] = sentences.apply(lambda x : int(x[\"dep\"].index(\"ROOT\")), axis=1)\n",
    "        sentences[\"root_word\"] = sentences.apply(lambda x : x[\"text\"][x[\"root_index\"]], axis=1)\n",
    "        sentences = sentences.rename(columns={\"text\": \"sentence\"})\n",
    "        final_df = pd.merge(final_df, sentences, on='sent_index', sort=False)\n",
    "        final_df[\"entity_1_index\"] = final_df.apply(lambda x : getIndex(x, x['sentence'], x['entity_pairs'][0]), axis=1)\n",
    "        final_df[\"entity_2_index\"] = final_df.apply(lambda x : getIndex(x, x['sentence'], x['entity_pairs'][1]), axis=1)\n",
    "        final_df[\"entity_distance\"] = final_df.apply(lambda x : x['entity_2_index'] - x['entity_1_index'], axis=1)\n",
    "        final_df[\"no_words_before_entity_1\"] = final_df[\"entity_1_index\"] - 1 \n",
    "        final_df[\"no_words_after_entity_2\"] = final_df[\"sentence_length\"] - final_df[\"entity_2_index\"] - 1\n",
    "\n",
    "        ## Calculating root-entity distances for each sentence\n",
    "        final_df[\"entity_1_root_distance\"] = final_df.apply(lambda x: x['root_index'] - x['entity_1_index'], axis=1)\n",
    "        final_df[\"entity_2_root_distance\"] = final_df.apply(lambda x: x['entity_2_index'] - x['root_index'], axis=1)\n",
    "\n",
    "        # Expand tuples\n",
    "        final_df[['entity 1 name', 'entity 2 name']] = final_df['entity_pairs'].apply(pd.Series)\n",
    "\n",
    "        final_df[['entity_type_1', 'entity_type_2']] = final_df['ent_type_pairs'].apply(pd.Series)\n",
    "        final_df[['entity_pos_1', 'entity_pos_2']] = final_df['pos_pairs'].apply(pd.Series)\n",
    "        final_df[['entity_dep_1', 'entity_dep_2']] = final_df['dep_pairs'].apply(pd.Series)\n",
    "        # final_df[['entity_tag_1', 'entity_tag_2']] = final_df['tag_pairs'].apply(pd.Series)  ## For  ACE2004, ACE2005, tacred, kbp37 as no tag exists \n",
    "        final_df[[\"shortest_distance\", \"shortest_path\"]] = final_df.apply(lambda x : generateNetwork(x[\"sentence\"], x[\"entity_1_index\"], x[\"entity_2_index\"]), axis = 1, result_type=\"expand\")\n",
    "        final_df[\"entity_type_1\"] = final_df[\"entity_type_1\"].apply(lambda x : x.split(\"-\")[0])\n",
    "        final_df[\"entity_type_2\"] = final_df[\"entity_type_2\"].apply(lambda x : x.split(\"-\")[0])\n",
    "\n",
    "        final_df = final_df[~final_df['entity_pos_1'].isin(pos_ignore_list)]\n",
    "        final_df = final_df[~final_df['entity_pos_2'].isin(pos_ignore_list)]\n",
    "\n",
    "        display(final_df[[\"entity 1 name\",\"entity 2 name\", \"entity_pos_1\", \"entity_pos_2\", \"entity_type_1\", \"entity_type_2\"]])\n",
    "        # final_df = final_df.drop([ \"entity_pairs\", \"ent_type_pairs\", \"pos_pairs\", \"dep_pairs\", \"tag_pairs\"], axis = 1)  ## For ACE2004, ACE2005, tacred, kbp37 as no tag exists \n",
    "        final_df = final_df.drop([ \"entity_pairs\", \"ent_type_pairs\", \"pos_pairs\", \"dep_pairs\"], axis = 1)\n",
    "        return final_df\n",
    "    except :\n",
    "        print(\"Failed to execute file : \", file)\n",
    "        print(\"Error : \", sys.exc_info())\n",
    "        print(traceback.format_exc())\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "346ab79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesWithlabels(relation_file, tagged_tokens_file):\n",
    "    try:\n",
    "        final_df = getFeatures(tagged_tokens_file)\n",
    "        relations = pd.read_csv(relation_file)\n",
    "        relations = relations.rename(columns={\"ent1_text\" : \"entity 1 name\", \"ent2_text\" : \"entity 2 name\"})\n",
    "        result = final_df.merge(relations, on=[\"entity 1 name\", \"entity 2 name\"], sort=False)\n",
    "        result.drop_duplicates(subset=[\"sent_index\", \"entity 1 name\", \"entity 2 name\"], keep='first', inplace=True, ignore_index=True)\n",
    "        # if \"span\" not in result.keys():\n",
    "        result[\"label\"] = result[\"sent_index\"].apply(lambda x : 1 if isinstance(x, str) else 0)\n",
    "        # result[\"label\"] = result.apply(lambda x : 0 if x[\"rel_type\"] == \"no_relation\" else x[\"label\"], axis = 1)\n",
    "        return result\n",
    "    except:\n",
    "        print(\"Skipping run for : \", relation_file, tagged_tokens_file)\n",
    "        print(sys.exc_info())\n",
    "        # display(final_df)\n",
    "#         display(relations)\n",
    "        # print(traceback.format_exc())\n",
    "        return pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a23490d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ace2005\"\n",
    "# ground_truth_path = f\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /Dataset/{dataset}/ground_truth\"\n",
    "ground_truth_path = f\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /Dataset/{dataset}\"\n",
    "# tagged_token_path = f\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /Dataset/{dataset}/tagged_tokens\"\n",
    "tagged_token_path = f\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /Dataset/{dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e48f61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity 1 name</th>\n",
       "      <th>entity 2 name</th>\n",
       "      <th>entity_pos_1</th>\n",
       "      <th>entity_pos_2</th>\n",
       "      <th>entity_type_1</th>\n",
       "      <th>entity_type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wife</td>\n",
       "      <td>kids</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>group</td>\n",
       "      <td>hubbies</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>group</td>\n",
       "      <td>wife</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>hubbies</td>\n",
       "      <td>wife</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ex</td>\n",
       "      <td>boyfriend</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>parents</td>\n",
       "      <td>church</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>members</td>\n",
       "      <td>pond</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PER</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>members</td>\n",
       "      <td>church</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>pond</td>\n",
       "      <td>church</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>LOC</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ex</td>\n",
       "      <td>ex</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity 1 name entity 2 name entity_pos_1 entity_pos_2 entity_type_1  \\\n",
       "6    wife          kids          NOUN         NOUN         PER            \n",
       "34   group         hubbies       NOUN         NOUN         PER            \n",
       "36   group         wife          NOUN         NOUN         PER            \n",
       "50   hubbies       wife          NOUN         NOUN         PER            \n",
       "54   ex            boyfriend     PROPN        NOUN         PER            \n",
       "..   ..                  ...       ...         ...         ...            \n",
       "509  parents       church        NOUN         NOUN         PER            \n",
       "511  members       pond          NOUN         ADJ          PER            \n",
       "512  members       church        NOUN         NOUN         PER            \n",
       "515  pond          church        ADJ          NOUN         LOC            \n",
       "535  ex            ex            NOUN         NOUN         PER            \n",
       "\n",
       "    entity_type_2  \n",
       "6    PER           \n",
       "34   PER           \n",
       "36   PER           \n",
       "50   PER           \n",
       "54   PER           \n",
       "..   ...           \n",
       "509  ORG           \n",
       "511  LOC           \n",
       "512  ORG           \n",
       "515  ORG           \n",
       "535  PER           \n",
       "\n",
       "[116 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_type_1</th>\n",
       "      <th>entity_type_2</th>\n",
       "      <th>rel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I, love, my, wife, ,, and, the, kids, get, along, just, fine, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[My, wife, belongs, to, a, support, group, ,, and, just, for, fun, ,, they, all, googled, their, hubbies, ex, 's, .,  ]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Somehow, ,, this, lead, me, to, googling, my, ex, 's, boyfriend, ,, call, him, B.]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[And, there, he, was, ,, talking, about, plans, with, his, wife, and, kids, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[To, me, ,, B, was, just, this, one, dimensional, guy, that, was, being, dragged, along, by, my, exwife, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]</td>\n",
       "      <td>PER</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Membership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]</td>\n",
       "      <td>LOC</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    sentence  \\\n",
       "0   [I, love, my, wife, ,, and, the, kids, get, along, just, fine, .]                                                                                                                          \n",
       "1   [My, wife, belongs, to, a, support, group, ,, and, just, for, fun, ,, they, all, googled, their, hubbies, ex, 's, .,  ]                                                                    \n",
       "2   [Somehow, ,, this, lead, me, to, googling, my, ex, 's, boyfriend, ,, call, him, B.]                                                                                                        \n",
       "3   [And, there, he, was, ,, talking, about, plans, with, his, wife, and, kids, .]                                                                                                             \n",
       "4   [To, me, ,, B, was, just, this, one, dimensional, guy, that, was, being, dragged, along, by, my, exwife, .]                                                                                \n",
       "..                                                                                                          ...                                                                                \n",
       "57  [My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]   \n",
       "58  [My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]   \n",
       "59  [My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]   \n",
       "60  [My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]   \n",
       "61  [My, family, thinks, my, ex, is, pond, scum, but, because, my, parents, are, still, members, at, the, same, church, ,, they, have, to, see, my, ex, and, his, new, wife, every, week, .]   \n",
       "\n",
       "   entity_type_1 entity_type_2     rel_type  \n",
       "0   PER           PER           no_relation  \n",
       "1   PER           PER           no_relation  \n",
       "2   PER           PER           no_relation  \n",
       "3   PER           PER           no_relation  \n",
       "4   PER           PER           no_relation  \n",
       "..  ...           ...                   ...  \n",
       "57  PER           ORG           no_relation  \n",
       "58  PER           PER           no_relation  \n",
       "59  PER           ORG           no_relation  \n",
       "60  PER           ORG           Membership   \n",
       "61  LOC           ORG           no_relation  \n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(tagged_token_path)\n",
    "features_with_labels = pd.DataFrame()\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".csv\"):\n",
    "        if dataset in [\"ace2004\", \"ace2005\"]:\n",
    "            file = file.split(\".csv_\")[0]\n",
    "            tagged_tokens_file = f\"{tagged_token_path}/{file}.csv_tagged_tokens.csv\"\n",
    "            relation_file = f\"{ground_truth_path}/{file}.csv_gt_relations.csv\"\n",
    "        else:\n",
    "            tagged_tokens_file = f\"{tagged_token_path}/{file}\"\n",
    "            relation_file = f\"{ground_truth_path}/{file}\"\n",
    "        temp = getFeaturesWithlabels(relation_file, tagged_tokens_file)\n",
    "        features_with_labels = pd.concat([features_with_labels, temp])\n",
    "        \n",
    "        break\n",
    "features_with_labels[[\"sentence\", \"entity_type_1\", \"entity_type_2\", \"rel_type\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cab0a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_labels.to_csv(\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /ResponsibleRelationExtraction/Features/features_\"+dataset+\"-binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537051b3-8a2e-4712-a5ac-32dd4101d03b",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a1fac8c-1087-44e9-abc2-9a59044f5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full():\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 2000)\n",
    "    pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "print_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2902de20-a319-4258-a91b-27e63c8eeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get complete sentence\n",
    "features_with_labels[\"sentence\"] = features_with_labels[\"sentence\"].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c1610e6-84fa-44e8-8807-26297fb0bc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity 1 name</th>\n",
       "      <th>entity 2 name</th>\n",
       "      <th>entity_type_1</th>\n",
       "      <th>entity_type_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It 'll take me awhile to get to thought stream...</td>\n",
       "      <td>me</td>\n",
       "      <td>me</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love my wife , and the kids get along just f...</td>\n",
       "      <td>I</td>\n",
       "      <td>my</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do n't like my exwife .</td>\n",
       "      <td>I</td>\n",
       "      <td>my</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I 'll have to ask about B 's kid when my own k...</td>\n",
       "      <td>I</td>\n",
       "      <td>my</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know my first marriage had a lot of good adv...</td>\n",
       "      <td>I</td>\n",
       "      <td>my</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Kiichiro Toyoda founded the automaker in 1937 ...</td>\n",
       "      <td>manufacturer</td>\n",
       "      <td>automaker</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Kiichiro Toyoda founded the automaker in 1937 ...</td>\n",
       "      <td>manufacturer</td>\n",
       "      <td>father</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Kiichiro Toyoda founded the automaker in 1937 ...</td>\n",
       "      <td>manufacturer</td>\n",
       "      <td>his</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Kiichiro Toyoda founded the automaker in 1937 ...</td>\n",
       "      <td>automaker</td>\n",
       "      <td>automaker</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Kiichiro Toyoda founded the automaker in 1937 ...</td>\n",
       "      <td>Kiichiro Toyoda</td>\n",
       "      <td>his</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence    entity 1 name  \\\n",
       "0    It 'll take me awhile to get to thought stream...               me   \n",
       "1    I love my wife , and the kids get along just f...                I   \n",
       "2                            I do n't like my exwife .                I   \n",
       "3    I 'll have to ask about B 's kid when my own k...                I   \n",
       "4    I know my first marriage had a lot of good adv...                I   \n",
       "..                                                 ...              ...   \n",
       "117  Kiichiro Toyoda founded the automaker in 1937 ...     manufacturer   \n",
       "118  Kiichiro Toyoda founded the automaker in 1937 ...     manufacturer   \n",
       "119  Kiichiro Toyoda founded the automaker in 1937 ...     manufacturer   \n",
       "120  Kiichiro Toyoda founded the automaker in 1937 ...        automaker   \n",
       "121  Kiichiro Toyoda founded the automaker in 1937 ...  Kiichiro Toyoda   \n",
       "\n",
       "    entity 2 name entity_type_1 entity_type_2  label  \n",
       "0              me           PER           PER      0  \n",
       "1              my           PER           PER      0  \n",
       "2              my           PER           PER      0  \n",
       "3              my           PER           PER      0  \n",
       "4              my           PER           PER      0  \n",
       "..            ...           ...           ...    ...  \n",
       "117     automaker           ORG           ORG      0  \n",
       "118        father           ORG           PER      0  \n",
       "119           his           ORG           PER      0  \n",
       "120     automaker           ORG           ORG      0  \n",
       "121           his           PER           PER      0  \n",
       "\n",
       "[116320 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For Binary labels\n",
    "features_with_labels[features_with_labels[\"label\"].apply(lambda x : x==0)][[\"sentence\", \"entity 1 name\", \"entity 2 name\", \"entity_type_1\", \"entity_type_2\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04101432-9ada-45dd-b467-5873e52a91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Entity Type Labels\n",
    "ENT_TYPES = [\"PER\", \"GPE\", \"LOC\", \"ORG\"]\n",
    "def recode_entity_types(value):\n",
    "    if value.lower() in [\"person\", \"per\"]:\n",
    "        return \"PER\"\n",
    "    elif value.lower() in [\"organisation\", \"org\"]:\n",
    "        return \"ORG\"\n",
    "    elif value.lower() in [\"gpe\"]:\n",
    "        return \"GPE\"\n",
    "    elif value.lower() in [\"location\", \"loc\"]:\n",
    "        return \"LOC\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "    \n",
    "features_with_labels[\"entity_type_1\"] = features_with_labels[\"entity_type_1\"].apply(lambda x : recode_entity_types(x.split(\"-\")[0]))\n",
    "features_with_labels[\"entity_type_2\"] = features_with_labels[\"entity_type_2\"].apply(lambda x : recode_entity_types(x.split(\"-\")[0]))\n",
    "features_with_labels[\"en-label\"] = features_with_labels.apply(lambda x : f\"{x['entity_type_1']}-{x['entity_type_2']}\", axis=1)\n",
    "# features_with_labels[\"entity 1 type\"] = features_with_labels[\"entity 1 type\"].apply(lambda x : recode_entity_types(x.split(\"-\")[0]))\n",
    "# features_with_labels[\"entity 2 type\"] = features_with_labels[\"entity 2 type\"].apply(lambda x : recode_entity_types(x.split(\"-\")[0]))\n",
    "# features_with_labels[\"en-label\"] = features_with_labels.apply(lambda x : f\"{x['entity 1 type']}-{x['entity 2 type']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1ca7a3c-c2f4-4689-bfee-91a3b1cf1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_relation' 'Family' 'Located' 'User-Owner-Inventor-Manufacturer'\n",
      " 'Lasting-Personal' 'Membership' 'Employment' 'Business'\n",
      " 'Citizen-Resident-Religion-Ethnicity' 'Student-Alum' 'Geographical'\n",
      " 'Investor-Shareholder' 'Sports-Affiliation' 'Org-Location' 'Subsidiary'\n",
      " 'Near' 'Artifact' 'Founder' 'Ownership']\n"
     ]
    }
   ],
   "source": [
    "## For support \n",
    "features_with_labels = features_with_labels[features_with_labels['rel_type'].notna()]\n",
    "grouped = features_with_labels.groupby(['rel_type'])\n",
    "values = grouped[\"rel_type\"].value_counts()\n",
    "# grouped[\"support\"] = grouped[\"en-label\"].apply(lambda x : values[x].values[0])\n",
    "df = grouped.head(3)[[\"rel_type\", \"sentence\", \"entity 1 name\", \"entity 2 name\", \"entity_type_1\", \"entity_type_2\"]].sort_values(by = \"rel_type\")\n",
    "## Calculate support of each type\n",
    "# df[\"support\"] = df[\"label\"].apply(lambda x : values[x].values[0])\n",
    "# df[\"support\"] = df[\"en-label\"].apply(lambda x : values[x].values[0])\n",
    "df[\"support\"] = df[\"rel_type\"].apply(lambda x : values[x].values[0])\n",
    "df[\"dataset\"] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e6a9a507-bf89-4c17-9168-6242b5a51586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/anishajauhari/Desktop/Sem 4/Independent Study /Examples/\"+dataset+\"_examples_relations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ea926-f54a-4ddb-a06b-fe645c147900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77779e9-5b4a-494e-9c63-b478cbf8df68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
